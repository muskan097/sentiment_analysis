{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"Restaurant_reviews.tsv\",delimiter=\"\\t\")\n",
    "#test_data=pd.read_csv(\"C:/Users/ASUS/Desktop/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  1000 non-null   object\n",
      " 1   Liked   1000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review    0\n",
       "Liked     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.50025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Liked\n",
       "count  1000.00000\n",
       "mean      0.50000\n",
       "std       0.50025\n",
       "min       0.00000\n",
       "25%       0.00000\n",
       "50%       0.50000\n",
       "75%       1.00000\n",
       "max       1.00000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d2efb09240>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train_data[\"Liked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: Liked, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Liked\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('all')\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=WordNetLemmatizer()\n",
    "corpus=[]\n",
    "for i in range(0,len(train_data)):\n",
    "    review = re.sub(pattern='[^a-zA-Z]',repl=' ', string=train_data['Review'][i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=[ls.lemmatize(word) for word in review if not word in stopwords.words('english')]\n",
    "    review=\" \".join(review)\n",
    "    corpus.append(review)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow loved place',\n",
       " 'crust good',\n",
       " 'tasty texture nasty',\n",
       " 'stopped late may bank holiday rick steve recommendation loved',\n",
       " 'selection menu great price',\n",
       " 'getting angry want damn pho',\n",
       " 'honeslty taste fresh',\n",
       " 'potato like rubber could tell made ahead time kept warmer',\n",
       " 'fry great',\n",
       " 'great touch']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv=TfidfVectorizer()\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = train_data.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Scores ----\n",
      "Accuracy score is: 77.0%\n",
      "Precision score is: 0.77\n",
      "Recall score is: 0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "score1 = accuracy_score(y_test,y_pred)\n",
    "score2 = precision_score(y_test,y_pred)\n",
    "score3= recall_score(y_test,y_pred)\n",
    "print(\"---- Scores ----\")\n",
    "print(\"Accuracy score is: {}%\".format(round(score1*100,2)))\n",
    "print(\"Precision score is: {}\".format(round(score2,2)))\n",
    "print(\"Recall score is: {}\".format(round(score3,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72, 25],\n",
       "       [21, 82]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\naive_bayes.py:512: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-26f16c5fbd8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0msub_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0my_pred1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msub_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mprevious_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mhyper_classifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msub_classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "hyper_classifier=MultinomialNB(alpha=0.1)\n",
    "import numpy as np\n",
    "previous_score=0\n",
    "for alpha in np.arange(0,1,0.1):\n",
    "    sub_classifier=MultinomialNB(alpha=alpha)\n",
    "    sub_classifier.fit(X_train,y_train)\n",
    "    y_pred1=sub_classifier.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test, y_pred1)\n",
    "    if score>previous_score:\n",
    "        hyper_classifier=sub_classifier\n",
    "        print(\"Alpha: {}, Score : {}\".format(alpha,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MultinomialNB(alpha=0.9)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred3 = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(sample_review):\n",
    "    sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ', string = sample_review)\n",
    "    sample_review = sample_review.lower()\n",
    "    sample_review_words = sample_review.split()\n",
    "    sample_review_words = [word for word in sample_review_words if not word in set(stopwords.words('english'))]\n",
    "    ps = PorterStemmer()\n",
    "    final_review = [ps.stem(word) for word in sample_review_words]\n",
    "    final_review = ' '.join(final_review)\n",
    "\n",
    "    temp = cv.transform([final_review]).toarray()\n",
    "    return classifier.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_review = ' the place was very badbut the food was tasty '\n",
    "\n",
    "if predict_sentiment(sample_review):\n",
    "    print('This is a POSITIVE review.')\n",
    "else:\n",
    "    print('This is a NEGATIVE review!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-2a3b96a98ab3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"airfare.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'rf1' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename=\"sentiment.pkl\"\n",
    "pickle.dump(classifier,file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
